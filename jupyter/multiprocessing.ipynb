{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import multiprocessing\n",
    "import xlrd\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:1542277652.8674157\n",
      "index: 0 - 8700 of 8964- filenames--['log', 'test', 'resnet', 'Alex_net', 'UCMerced']\n",
      "index: 5 - 8700 of 8964- filenames--['Work', 'test01', '.git']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 查找文件夹和文件类\n",
    "\n",
    "\n",
    "def pf(files):\n",
    "    print('%s-%s' % (os.getpid(), os.getppid()))\n",
    "    print(files)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "class Search_files(object):\n",
    "    \"\"\"docstring for Search_files\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Search_files, self).__init__()\n",
    "        # self.arg = arg\n",
    "        # source_dirs\n",
    "\n",
    "    def search(self, filename, source_dirs, files=True, all_files=False):\n",
    "        dir_file_list = ['dirs', 'files']\n",
    "        index = 1 if files else 0\n",
    "        print('Search_files:%s-%s-,filename:%s' %\n",
    "              (os.getpid(), os.getppid(), filename))\n",
    "        if all_files:\n",
    "            find_file_list = []\n",
    "        # pdb.set_trace()\n",
    "        for soru_dir in source_dirs:\n",
    "            for fpathe, dir_file_list[0], dir_file_list[1] in os.walk(soru_dir):\n",
    "                if filename in dir_file_list[index]:\n",
    "                    find_file = fpathe + '\\\\' + filename\n",
    "                    if all_files:\n",
    "                        find_file_list.append(find_file)\n",
    "                    else:\n",
    "                        return find_file\n",
    "        if all_files:\n",
    "            print(filename, find_file_list)\n",
    "            return find_file_list\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "    def multi_thread_search(self, result, thread_num=8, *args, **kwargs):\n",
    "        index = 0\n",
    "        print('%s-%s-thread_num:%d,filenames:%s' %\n",
    "              (os.getpid(), os.getppid(), thread_num, kwargs['filenames']))\n",
    "        thr_pool = ThreadPool(thread_num)\n",
    "        filenames = kwargs.pop('filenames')\n",
    "        while index < len(filenames):\n",
    "            kwargs['filename'] = filenames[index]\n",
    "            print('%s-%s-thread_num:%d,filename:%s' %\n",
    "                  (os.getpid(), os.getppid(), thread_num, kwargs['filename']))\n",
    "            find_result = thr_pool.apply_async(\n",
    "                func=self.search, args=args, kwds=kwargs)\n",
    "            print('%s-%s-%s-' % (os.getpid(), os.getppid(),\n",
    "                                 kwargs['filename']), find_result.get())\n",
    "            if isinstance(result, type(multiprocessing.Manager().Queue())):\n",
    "                f.put([filenames[index], find_result.get()])\n",
    "            elif isinstance(result, list):\n",
    "                result.append([filenames[index], find_result.get()])\n",
    "            else:\n",
    "                print('Error!')\n",
    "            index += 1\n",
    "        thr_pool.close()\n",
    "        thr_pool.join()\n",
    "\n",
    "    def fast_search(self, filenames, target, pool_num=multiprocessing.cpu_count() // 2, *args, **kwargs):\n",
    "        index = 0\n",
    "        manager = multiprocessing.Manager()\n",
    "        queue = manager.Queue()\n",
    "        pro_pool = multiprocessing.Pool(pool_num)\n",
    "        # pro_pool.apply_async(func = target,args = (queue,))\n",
    "        thread_num = kwargs['thread_num']\n",
    "        while index < len(filenames):\n",
    "            if index + thread_num < len(filenames):\n",
    "                kwargs['filenames'] = filenames[index:index + thread_num]\n",
    "            else:\n",
    "                kwargs['filenames'] = filenames[index:]\n",
    "            print('index: %d - %s of %s- filenames--%s' %\n",
    "                  (index, os.getpid(), os.getppid(), kwargs['filenames']))\n",
    "            pro_pool.apply_async(\n",
    "                func=self.multi_thread_search, args=(queue,), kwds=kwargs)\n",
    "            # pro_pool.apply_async(func=pf, args=(kwargs['filenames'],))\n",
    "            index += thread_num\n",
    "        pro_pool.close()\n",
    "        pro_pool.join()\n",
    "\n",
    "\n",
    "def main():\n",
    "    table = data.sheets()[0]\n",
    "    nrows = table.nrows\n",
    "    # 需要复制的文件夹名称列表\n",
    "    foldername_lists = table.col_values(0)\n",
    "    data = xlrd.open_workbook(\n",
    "        r'X:\\DATA\\1-中间成果\\接边参考数据\\拷贝脚本-menzecheng\\伊朗与土耳其接边--最终提取图幅列表-用于拷贝脚本.xlsx')\n",
    "    # 源路径\n",
    "    fromDirList = [r'X:\\quanqiu02_2017\\2-成果数据省局提供\\陕西局\\伊朗北部\\DSM', ]\n",
    "    toDir = r'X:\\DATA\\1-中间成果\\接边参考数据\\与2018年第二批汇交数据接边\\伊朗与土耳其接边\\DSM-DDG'\n",
    "\n",
    "\n",
    "def func(queue):\n",
    "    pdb.set_trace()\n",
    "    while os.getppid():\n",
    "        if not queue.empty():\n",
    "            for i in range(queue.qsize()):\n",
    "                print(queue.get())\n",
    "        else:\n",
    "            time.sleep(3)\n",
    "if __name__ == \"__main__\":\n",
    "    print('start time:%s' % (time.time()))\n",
    "    fromDirList = [r'D:/', ]\n",
    "    testcp = Search_files()\n",
    "    print(testcp.fast_search(target=func, filenames=['log', 'test', 'resnet', 'Alex_net', 'UCMerced', 'Work', 'test01', '.git'],\n",
    "                             thread_num=5, pool_num=2, files=False, source_dirs=fromDirList, all_files=1))\n",
    "    print('end time:%s' % (time.time()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
